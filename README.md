## Running the DLinkMaP_v2 Pipeline

This repository based off of the DLinkMaP QTL mapping repository by rmathur87. All code is in its original format, but this version provides:
1. Standardized phenotype data headers and a parameter/configuration template.
2. Explicit assumptions and pipelines
3. An additional first step to format data files

All hidden assumptions in the original repo have been made explicit.

DLinkMaP_clean/
  README.md
  renv.lock / DESCRIPTION      # optional, but recommended
  .gitignore

  config/
    params.csv                 # one run config (paths + options)
    schemas/
      phenotype_required_cols.txt

  data/
    phenotypes/                # cleaned phenotype CSVs (not committed)
      tg.csv
      pc1_tg.csv

  src/
    dlinkmap/                  # code you copy from DLinkMaP (the engine)
      mapping/
        MAP_general.R
        MAPFun_general.R
        FUN.R
        gradMM.R
        MM_Process.R
        QC.R
        QTL_Process.R
        NullSetUpBla_TG_Trehalose_Weights.R
      # (no parallelizer)

    v2/                        # your glue code (small, readable)
      validate_input.R
      run_null.R
      run_map.R
      run_all.R
      utils.R

  outputs/
    nulls/                     # null .RData (not committed)
    qtl/                       # mapping outputs (not committed)
    logs/                      # logs (not committed)

  tests/
    smoke_test.R               # optional


The pipeline has **three conceptual steps**, run in order.

---

### 0. Prerequisites

* R installed
* All R packages required by the original DLinkMaP mapping scripts installed
* Original `DLinkMaP` repo available locally (used as reference / code source)

This repo does **not** modify the original DLinkMaP repo.

---

## 1. Prepare phenotype data (formatting step)

All phenotype data must be converted into a **standardized CSV format** before analysis.

### Canonical header format (dot-style)

All phenotype CSVs used by this pipeline must contain:

```
vial
cross.type
female.line
male.line
food.type
month.crossed
cross.number
y
```

Plus **exactly one** of:

* `plate` (for TG / trehalose / plate-based assays)
* `number.weighed` (for weight / averaged phenotypes)

### Where formatted data lives

Cleaned phenotype files go in:

```
data/phenotypes_clean/
```

Example:

```
data/phenotypes_clean/tg_formatted_dots.csv
```

The file `tg_formatted_dots.csv` was generated by standardizing headers based on
`phenotypes/TG/TG_data_updated_5_8_13_formatted.csv` from the original DLinkMaP repo.

Raw data is **not tracked** and should not be committed.

---

## 2. Generate the null model (Pipeline 1)

Each phenotype vector (`y`) requires its **own null model**.

From the repo root:

```bash
mkdir -p outputs/nulls outputs/logs

Rscript src/dlinkmap/mapping/NullSetUpBla_TG_Trehalose_Weights.R \
  data/phenotypes_clean/tg_formatted_dots.csv \
  tg \
  outputs/nulls \
  > outputs/logs/null_tg.log 2>&1
```

### What this does

* Fits the baseline mixed model (no QTLs)
* Saves a `.RData` file in `outputs/nulls/`
* This file encodes the *model context* and the phenotype vector

Confirm output:

```bash
ls outputs/nulls
```

You should see something like:

```
Null_tg.RData
```

---

## 3. Run QTL mapping (Pipeline 2)

Each QTL scan is controlled by a **params CSV** (run configuration).

### Params file

Create or copy a params file in:

```
config/
```

Example:

```
config/params_tg.csv
```

The params file defines:

* where the mapping code lives
* which phenotype file to use
* which null file to load
* where outputs should go

Each run uses **one params file**.
New runs = copy the params file and edit paths.

---

### Run mapping

From the repo root:

```bash
mkdir -p outputs/qtl/tg_run

Rscript src/dlinkmap/mapping/MAP_general.R \
  config/params_tg.csv \
  > outputs/logs/tg_run.log 2>&1
```

Outputs will appear in:

```
outputs/qtl/tg_run/
```

Logs are written to:

```
outputs/logs/tg_run.log
```

---

## Mental model of the pipeline

* **Formatting step**: raw data → standardized phenotype CSV
* **Null step**: standardized CSV → baseline mixed model (`.RData`)
* **Mapping step**: null + phenotype → QTL scan results

Nothing is inferred implicitly.
Every dependency is named and passed explicitly.

---

## Notes

* This repo uses **dot-style headers only** (no spaces).
* The original DLinkMaP repo remains untouched.
* Raw data and outputs are not committed.
* Reproducibility comes from:

  * standardized input schema
  * explicit null files
  * per-run params CSVs

---
Adding a New Phenotype (including PCA-derived phenotypes)

This pipeline treats phenotypes as data vectors, not as model definitions.
Adding a new phenotype means producing a new y column and running the same two-stage pipeline.

There is no special PCA logic in the mapping code.

What “a new phenotype” means here

A new phenotype is:

a new numeric vector assigned to column y

measured on the same experimental units

using the same design variables (cross, lines, diet, month, etc.)

If those conditions hold, the pipeline does not care whether y is:

TG concentration

weight

PC1 from a PCA

any other derived quantity

Step-by-step: adding a new phenotype
1. Create a new phenotype CSV

Start from an existing standardized phenotype file (e.g. TG).

For a PCA-derived phenotype:

compute PCA outside this pipeline

create a new CSV where:

y = PC1 (or PC2, etc.)

all other columns are unchanged

Example location:

data/phenotypes_clean/tg_pc1.csv


The header must still match the canonical schema:

vial,cross.type,female.line,male.line,food.type,month.crossed,cross.number,plate,y


Only the values of y change.

2. Generate a new null model (required)

Each phenotype vector requires its own null model, even if the model structure is identical.

Run the null step again:

Rscript src/dlinkmap/mapping/NullSetUpBla_TG_Trehalose_Weights.R \
  data/phenotypes_clean/tg_pc1.csv \
  tg \
  outputs/nulls \
  > outputs/logs/null_tg_pc1.log 2>&1


This will produce a new null file, e.g.:

outputs/nulls/Null_tg.RData


(If you want to distinguish nulls by phenotype, rename the file or keep them in separate folders.)

3. Create a new params file for the run

Copy an existing params file:

config/params_tg.csv → config/params_tg_pc1.csv


Edit only:

fileName → path to tg_pc1.csv

nullFile → the null file produced in step 2

outDir → a new output directory

Everything else stays the same.

Each params file corresponds to one run.

4. Run mapping
Rscript src/dlinkmap/mapping/MAP_general.R \
  config/params_tg_pc1.csv \
  > outputs/logs/tg_pc1.log 2>&1


Outputs will appear in the directory specified by outDir.

Notes on model context

PCA of TG / trehalose data should use the TG model context (tg)

PCA of non–plate-based data should use the generic model context

Model context determines nuisance effects (plate, weights), not trait identity

The pipeline assumes you choose the correct context when generating the null.

Summary

To add a new phenotype:

Create a new standardized CSV with a new y

Generate a matching null model

Copy and edit a params file

Run mapping

No other code changes are required.

If this repo snags, please contact the developer (Lcohen5)